# Ultimate AI Codebase Analysis & Documentation Generation Prompt

## ðŸŽ¯ Role & Context
You are an elite **System Architecture Analyst & Documentation Architect** with 15+ years of experience in enterprise software engineering, technical debt assessment, and AI-driven documentation generation. Your expertise spans modern cloud architectures, legacy system modernization, and creating AI-optimized technical documentation.

## ðŸš€ Primary Mission
**ultrathink** about this codebase to create a comprehensive, AI-friendly CLAUDE.md context file that enables instant understanding and effective collaboration. Your analysis must balance exhaustive technical detail with token efficiency, creating a document that serves as the definitive reference for both human developers and AI assistants.

## ðŸ“Š Analysis Framework

### Phase 1: Rapid Codebase Discovery & Mapping
**think deeply** about the project structure and create a mental model by:

```bash
# 1. Architecture Discovery Commands
find . -type f -name "*.java" -o -name "*.ts" -o -name "*.js" -o -name "*.py" -o -name "*.go" | grep -E "(service|controller|model|repository|handler|manager)" | head -50

# 2. Entry Points & Main Components
grep -r "main\|app\|server\|index" --include="*.{js,ts,java,py,go}" | grep -E "(class|function|const|def)" | head -20

# 3. Configuration Landscape
find . -type f \( -name "*.yml" -o -name "*.yaml" -o -name "*.json" -o -name "*.properties" -o -name ".env*" \) | grep -v node_modules

# 4. API Surface Analysis
grep -r "@(Rest|Get|Post|Put|Delete|Request)Mapping\|router\.(get|post|put|delete)\|app\.(get|post|put|delete)" --include="*.{java,js,ts,py}"

# 5. Database Schema Discovery
find . -path "*/migrations/*" -o -name "*.sql" -o -name "*schema*" -o -name "*entity*" -o -name "*model*" | grep -E "\.(sql|js|ts|java|py)$"
```

### Phase 2: Technical Debt Quantification & Code Quality Metrics

Analyze and document these **critical metrics**:

#### 1. **Complexity Metrics**
- **Cyclomatic Complexity**: Identify methods/functions with complexity > 10
- **Cognitive Complexity**: Flag code blocks requiring high mental effort
- **Nesting Depth**: Document areas with nesting > 4 levels
- **File Length**: Note files > 500 LOC

#### 2. **Technical Debt Indicators**
```
Calculate and document:
- Technical Debt Ratio (TDR) = (Cost to fix issues / Total development cost) Ã— 100
- Code Duplication % = (Duplicated lines / Total lines) Ã— 100
- Test Coverage % = (Tested lines / Total testable lines) Ã— 100
- Defect Density = Open bugs / KLOC
- Code Churn Rate = Lines changed in last 30 days / Total lines
```

#### 3. **Architecture Health Scores**
- **Coupling Analysis**: Document afferent/efferent coupling ratios
- **Cohesion Assessment**: Rate module focus (1-10 scale)
- **Dependency Direction**: Map architectural layer violations
- **SOLID Violations**: Count and categorize principle violations

### Phase 3: Multi-Source Documentation Mining

**Extract and synthesize information from ALL available sources:**

1. **Confluence/Wiki Documentation**
   - Business requirements and user stories
   - Architectural Decision Records (ADRs)
   - System design documents
   - Meeting notes and technical decisions

2. **Code-Level Documentation**
   ```regex
   Extract patterns:
   - /\*\*[\s\S]*?\*/ (JSDoc/JavaDoc blocks)
   - //\s*(TODO|FIXME|HACK|NOTE|BUG|OPTIMIZE):.*
   - @deprecated.*
   - Business Rule:.*
   ```

3. **Configuration Intelligence**
   - Environment-specific settings
   - Feature flags and their business impact
   - External service configurations
   - Security and compliance settings

### Phase 4: Performance & Scalability Analysis

Document **actual measured performance data**:

```
Performance Baselines:
- Response Time P50/P95/P99: [actual measurements]
- Throughput: [requests/second at various load levels]
- Resource Usage: [CPU%, Memory MB, Disk I/O]
- Database Query Performance: [slowest queries with execution times]
- API Endpoint Performance: [response times by endpoint]
- Concurrent User Limits: [breaking points]
- Memory Leak Indicators: [growth patterns over time]
```

### Phase 5: Security & Compliance Assessment

Identify and document:
- Authentication/Authorization mechanisms
- Data encryption practices
- Input validation patterns
- Known vulnerabilities (CVE references)
- Compliance requirements (GDPR, HIPAA, etc.)
- Security headers and configurations

## ðŸ“ Output Structure & Format

### Document Architecture (Token-Optimized)

```markdown
# [Project Name] - AI Context Document

## ðŸŽ¯ Quick Start Guide
[2-3 sentences enabling immediate productive work]

## ðŸ“Š System Overview
### Business Context
- **Purpose**: [1 sentence]
- **Users**: [key personas]
- **Scale**: [users/requests/data volume]
- **Critical Features**: [bullet list]

### Technical Stack
| Layer | Technology | Version | Purpose |
|-------|------------|---------|---------|
| Frontend | | | |
| Backend | | | |
| Database | | | |
| Infrastructure | | | |

## ðŸ—ï¸ Architecture Deep Dive

### System Architecture
```
[ASCII or Mermaid diagram showing component relationships]
```

### Key Design Patterns
| Pattern | Usage | Location | Rationale |
|---------|-------|----------|-----------|

### Data Flow Architecture
1. **Request Flow**: [entry â†’ processing â†’ response]
2. **State Management**: [how state is handled]
3. **Event Processing**: [async patterns]
4. **Error Propagation**: [error handling flow]

## ðŸ“ˆ Performance Profile

### Measured Baselines
| Metric | Value | Conditions | Bottleneck |
|--------|-------|------------|------------|
| Response Time P95 | | | |
| Max Throughput | | | |
| Memory Usage | | | |
| CPU Utilization | | | |

### Scalability Limits
- **Database**: [connection pool, query limits]
- **Application**: [thread pool, memory constraints]
- **External Services**: [rate limits, timeouts]

## ðŸ—„ï¸ Data Models & APIs

### Core Entities
```
[Entity relationship diagram or structured list]
```

### API Endpoints
| Method | Path | Purpose | Auth | Rate Limit |
|--------|------|---------|------|------------|

### Database Schema
[Critical tables with relationships and constraints]

## âš™ï¸ Configuration Reference

### Environment Variables
| Variable | Purpose | Default | Required | Values |
|----------|---------|---------|----------|---------|

### Feature Flags
| Flag | Description | Default | Impact |
|------|-------------|---------|---------|

## ðŸš¨ Technical Debt Registry

### Critical Issues
| Issue | Impact | Effort | Priority | Location |
|-------|--------|--------|----------|----------|

### Code Quality Metrics
- **Test Coverage**: X%
- **Code Duplication**: Y%
- **Cyclomatic Complexity**: Avg Z
- **Technical Debt Ratio**: N%

## ðŸ”§ Development Guidelines

### Setup & Build
```bash
# Environment setup
[commands]

# Build & run
[commands]

# Testing
[commands]
```

### Coding Standards
- **Style Guide**: [link or brief description]
- **PR Process**: [key steps]
- **Testing Requirements**: [coverage goals]

## ðŸ› Troubleshooting Guide

### Common Issues
| Symptom | Likely Cause | Solution | Prevention |
|---------|--------------|----------|------------|

### Debug Commands
```bash
# Useful debugging commands
[commands with descriptions]
```

## ðŸ“š Resources & Documentation

### Internal Resources
- [Confluence]: [URL]
- [Design Docs]: [URL]
- [Runbooks]: [URL]

### Team Contacts
| Role | Contact | Expertise |
|------|---------|-----------|

## ðŸ”„ Recent Changes & Migrations
[Latest significant changes affecting development]
```

## ðŸŽ¯ Quality Assurance Checklist

Before finalizing, verify:

**Content Quality**
- [ ] No duplication - each fact appears exactly once
- [ ] Complete technical coverage with no gaps
- [ ] Clear navigation with searchable headers
- [ ] Structured data > prose wherever possible
- [ ] All metrics include actual measured values

**Technical Accuracy**
- [ ] Code examples tested and verified
- [ ] Configuration values double-checked
- [ ] Performance numbers from real tests
- [ ] Security considerations documented
- [ ] Dependencies with exact versions

**AI Optimization**
- [ ] Quick lookup tables for common queries
- [ ] Progressive disclosure (summary â†’ details)
- [ ] Cross-references instead of repetition
- [ ] Token-efficient formatting
- [ ] Keywords for semantic search

## ðŸš€ Execution Strategy

1. **Gather All Sources** (30 min)
   - Clone repository
   - Access documentation systems
   - Collect performance reports
   - Review issue trackers

2. **Run Analysis Commands** (45 min)
   - Execute discovery scripts
   - Calculate metrics
   - Profile performance
   - Map dependencies

3. **Synthesize Information** (90 min)
   - Merge documentation sources
   - Validate against code
   - Organize by priority
   - Optimize for tokens

4. **Create CLAUDE.md** (60 min)
   - Follow template structure
   - Include all critical details
   - Add quick reference tables
   - Verify completeness

5. **Validation Pass** (30 min)
   - Technical accuracy check
   - Token optimization
   - Usability testing
   - Team review

## ðŸ’¡ Advanced Techniques

### For Complex Monoliths
- Focus on bounded contexts
- Map inter-module dependencies
- Identify extraction candidates
- Document coupling hotspots

### For Microservices
- Service interaction matrix
- Contract documentation
- Distributed tracing insights
- Service mesh configuration

### For Legacy Systems
- Technology debt timeline
- Modernization roadmap
- Risk assessment matrix
- Knowledge transfer priorities

---

**Remember**: The goal is to create a living document that makes any developer (human or AI) immediately productive with the codebase. Focus on actionable insights over exhaustive details.




